{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyNokDMWBO34t/acPY+z/WAs",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chasubeen/ML_lab/blob/main/2_Variational_Inference.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import time\n",
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "from scipy.special import digamma, polygamma, loggamma"
      ],
      "metadata": {
        "id": "SpkcsGAvAsYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Preprocessing**"
      ],
      "metadata": {
        "id": "badhYe8TjrpX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1-1. Load data**"
      ],
      "metadata": {
        "id": "_Gx_9utFkNiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUa6BHK3j0_6",
        "outputId": "0562471d-e8f9-4cf4-aa5d-5cf57690401b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data path\n",
        "\n",
        "train_path = \"/content/drive/MyDrive/ML_lab/2_LDA/data/pos_tag/train.txt\"\n",
        "test_path = \"/content/drive/MyDrive/ML_lab/2_LDA/data/pos_tag/test.txt\""
      ],
      "metadata": {
        "id": "TfZ8ZwHjjw6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(path):\n",
        "  raw = open(path, 'r').read().split('\\n') # 파일을 읽어와 줄마다 나누기\n",
        "  data, doc = list(), list()\n",
        "\n",
        "  for i, line in enumerate(raw):\n",
        "    if line.strip(): # 빈 줄이 아니면\n",
        "      word = line.split(' ')[0].lower() # 첫 번째 단어를 얻어온 후 소문자로 변환\n",
        "      doc.append(word)\n",
        "    else:\n",
        "      data.append(doc) # EOD(End Of Document)\n",
        "      doc = list()\n",
        "  data.append(doc) # 맨 마지막 문서 추가\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "rbh73TnykXzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "train_data = read_file(train_path)\n",
        "test_data = read_file(test_path)\n",
        "\n",
        "# 맨 마지막 문서는 제거\n",
        "del train_data[-1], test_data[-1]"
      ],
      "metadata": {
        "id": "PrbMLqzHkn_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1-2. Preprocess Data**"
      ],
      "metadata": {
        "id": "gPInqBrgmRB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# some words that we do not want to consider\n",
        "stopwords = [\"\",\" \"]"
      ],
      "metadata": {
        "id": "HG_s50dnmZnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## remove numbers, special characters, etc.\n",
        "# only consider words with alphabet\n",
        "\n",
        "def only_alphabet(corpus,stopword_list = stopwords):\n",
        "  data = list()\n",
        "  for doc in corpus:\n",
        "    temp = list()\n",
        "    for word in doc:\n",
        "      word = re.sub('[^a-z]', '', word) # non-alphabet 문자 제거(=> 정규표현식 활용)\n",
        "      if word not in stopwords:\n",
        "        temp.append(word)\n",
        "    data.append(temp)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "bJcrZC1XmeAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = only_alphabet(train_data)\n",
        "test_data = only_alphabet(test_data)"
      ],
      "metadata": {
        "id": "6Cgy8v8ompb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## count word occurrence in corpus\n",
        "\n",
        "def count_vocab(corpus):\n",
        "  vocab = defaultdict(int) # dictionary 형태로 word occurence를 기록\n",
        "  for doc in corpus:\n",
        "    for word in doc:\n",
        "      vocab[word] += 1\n",
        "\n",
        "  return vocab"
      ],
      "metadata": {
        "id": "vTT8x1YImv8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_count = count_vocab(train_data)"
      ],
      "metadata": {
        "id": "7y76zEHArmov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 특정 빈도수 이상인 단어들만 고려\n",
        "# sparse한 단어는 무시\n",
        "\n",
        "def vocab_top(vocab,cnt):\n",
        "  temp = defaultdict(int)\n",
        "  for voca, count in vocab.items():\n",
        "    if count > cnt:\n",
        "      temp[voca] = count\n",
        "\n",
        "  return temp"
      ],
      "metadata": {
        "id": "ggNlOiM1rqgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_count = vocab_top(vocab_count,cnt = 5)"
      ],
      "metadata": {
        "id": "Biqdzl-8sbsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## filter out low-occurrence words\n",
        "\n",
        "def filter_vocab(corpus,vocab):\n",
        "  data = list()\n",
        "  for doc in corpus:\n",
        "    temp = list()\n",
        "    for word in doc:\n",
        "      if word in vocab.keys():\n",
        "        temp.append(word)\n",
        "    if temp:\n",
        "      data.append(temp)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "QKFK8zuwsg9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = filter_vocab(train_data,vocab_count)\n",
        "test_data = filter_vocab(test_data,vocab_count)"
      ],
      "metadata": {
        "id": "d1PgDw-Ds5OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## construct voca-index-matching dictionary\n",
        "\n",
        "def voca_index(vocab):\n",
        "  vocab_to_index, index_to_vocab = dict(), dict()\n",
        "  for i, voca in enumerate(vocab.keys()):\n",
        "    vocab_to_index[voca] = i\n",
        "    index_to_vocab[i] = voca\n",
        "\n",
        "  return vocab_to_index, index_to_vocab"
      ],
      "metadata": {
        "id": "pl9QYCl0s82P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_t_i, i_t_v = voca_index(vocab_count)"
      ],
      "metadata": {
        "id": "4nJ2IzIttOtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## convert corpus-with-words to corpus-with-index\n",
        "\n",
        "def corpus_to_index(corpus,vocab_to_index):\n",
        "  data = list()\n",
        "  for doc in corpus:\n",
        "    temp = list()\n",
        "    for word in doc:\n",
        "      temp.append(vocab_to_index[word])\n",
        "    data.append(temp)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "bbbnUBVQtRba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_idx = corpus_to_index(train_data,v_t_i)\n",
        "test_data_idx = corpus_to_index(test_data,v_t_i)"
      ],
      "metadata": {
        "id": "ZlpCKhKvuR9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Modeling**"
      ],
      "metadata": {
        "id": "JLLADECRuh36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LDA_VI:\n",
        "  def __init__(self,docs, num_topic=10, vocab = None, alpha=1.,num_iter=100,lr=1e-3):\n",
        "    self.docs = docs\n",
        "    self.num_topic = num_topic\n",
        "    self.vocab = vocab\n",
        "    self.num_vocab = len(self.vocab)\n",
        "    self.num_docs = len(self.docs)\n",
        "\n",
        "    # Initialize alpha and beta\n",
        "    self.alpha = np.ones(self.num_topic)*(1/self.num_topic)\n",
        "    self.beta = np.ones((self.num_topic, self.num_vocab))*(1/self.num_vocab)\n",
        "    # beta 초기값 업데이트\n",
        "    for k in range(self.num_topic):\n",
        "      for v in range(self.num_vocab):\n",
        "        self.beta[k][v] += np.random.rand(1) * 0.01\n",
        "      # beta normailize 진행\n",
        "      for v in range(self.num_vocab):\n",
        "        self.beta[k][v] /= np.sum(self.beta[k])\n",
        "\n",
        "    # Initialize gamma and phi\n",
        "    self.gamma = np.ones((self.num_docs,self.num_topic))*(1/self.num_topic)\n",
        "    self.phi = np.ones((self.num_docs, self.num_vocab, self.num_topic))*(1/self.num_topic) # <- 수정\n",
        "\n",
        "    # Initialize z (topic assignments for words in documents)\n",
        "    self.z = list()\n",
        "    for doc in self.docs:\n",
        "      temp = list()\n",
        "      for word in doc:\n",
        "        temp.append(None)\n",
        "      self.z.append(temp)\n",
        "\n",
        "    # Initialize parameters for variational inference\n",
        "    self.num_iter = num_iter\n",
        "    self.lr = lr\n",
        "\n",
        "  def update_gamma(self):\n",
        "    ## Update gamma (document-topic distributions)\n",
        "    # d: document의 index\n",
        "    for d in range(self.num_docs):\n",
        "      for k in range(self.num_topic):\n",
        "        self.gamma[d,k] = self.alpha[k]\n",
        "        for n in range(len(self.docs[d])):\n",
        "          self.gamma[d,k] += self.phi[d,n,k]\n",
        "\n",
        "  def update_phi(self):\n",
        "    ## Update phi (topic-word distributions)\n",
        "    for d in range(self.num_docs):\n",
        "      for n in range(len(self.docs[d])):\n",
        "        for k in range(self.num_topic):\n",
        "          self.phi[d, n, k] = self.beta[k, self.docs[d][n]] * np.exp(digamma(self.gamma[d, k]))\n",
        "        # phi 정규화\n",
        "        for k in range(self.num_topic):\n",
        "          self.phi[d, n, k] /= np.sum(self.phi[d, n])\n",
        "\n",
        "  def update_beta(self):\n",
        "    ## Update beta(topic-word prior)\n",
        "    for k in range(self.num_topic):\n",
        "      for d in range(self.num_docs):\n",
        "        for n in range(len(self.docs[d])):\n",
        "          self.beta[k, self.docs[d][n]] += self.phi[d, n, k]\n",
        "      # beta 정규화\n",
        "      for v in range(self.num_vocab):\n",
        "        self.beta[k, v] /= np.sum(self.beta[k])\n",
        "\n",
        "  def update_alpha(self):\n",
        "    ## Update alpha(document-topic prior)\n",
        "    M = self.num_docs\n",
        "    g = np.zeros(self.num_topic) # gradient\n",
        "    H = np.zeros((self.num_topic, self.num_topic)) # Hessian matrix\n",
        "\n",
        "    for i in range(self.num_topic):\n",
        "      g[i] = M * ( digamma(np.sum(self.alpha)) - digamma(self.alpha[i]) )\n",
        "      for d in range(M):\n",
        "        g[i] += ( digamma(self.gamma[d, i]) - digamma(np.sum(self.gamma[d])) )\n",
        "      for j in range(self.num_topic):\n",
        "        H[i, j] = 0\n",
        "        if i == j:\n",
        "          H[i, j] -= M * polygamma(1, self.alpha[i])\n",
        "        H[i, j] += M * (polygamma(1, np.sum(self.alpha)))\n",
        "\n",
        "    # alpha 업데이트(=> Newton-Raphson)\n",
        "    deltaAlpha = np.dot(np.linalg.inv(H), g)\n",
        "    for k in range(self.num_topic):\n",
        "      self.alpha[k] -= deltaAlpha[k]\n",
        "\n",
        "  def e_step(self):\n",
        "    ## Perform E-step of the variational inference\n",
        "    self.update_phi()\n",
        "    self.update_gamma()\n",
        "\n",
        "  def m_step(self):\n",
        "    ## Perform M-step of the variational inference\n",
        "    self.update_beta()\n",
        "    self.update_alpha()\n",
        "\n",
        "  def compute_elbo(self):\n",
        "    ## Compute Evidence Lower Bound (ELBO)\n",
        "\n",
        "    # 필요한 파라미터 정의\n",
        "    elbo = 0\n",
        "    M = self.num_docs\n",
        "    k = self.num_topic\n",
        "\n",
        "    # 1번 수식\n",
        "    for d in range(M): # document\n",
        "      for n in range(len(self.docs[d])):\n",
        "        j = self.docs[d][n] # word idx\n",
        "        for i in range(k): # topic\n",
        "          elbo += self.phi[d, n, i] * np.log(self.beta[i, j])\n",
        "\n",
        "    # 2번 수식\n",
        "    for d in range(M):\n",
        "      for n in range(len(self.docs[d])):\n",
        "        for i in range(k):\n",
        "          elbo += self.phi[d, n, i] * (digamma(self.gamma[d, i]) - digamma(np.sum(self.gamma[d])))\n",
        "\n",
        "    # 3번 수식\n",
        "    for d in range(M):\n",
        "      elbo += loggamma(np.sum(self.alpha))\n",
        "      for i in range(k):\n",
        "        elbo -= loggamma(self.alpha[i])\n",
        "        elbo += (self.alpha[i] - 1) * (digamma(self.gamma[d, i]) - digamma(np.sum(self.gamma[d])))\n",
        "\n",
        "    # 4번, 5번 수식\n",
        "    for d in range(M):\n",
        "      elbo -= loggamma(np.sum(self.gamma[d]))\n",
        "      for i in range(k):\n",
        "        elbo += loggamma(np.sum(self.gamma[d, i]))\n",
        "        elbo -= (self.gamma[d, i] - 1)*( digamma(self.gamma[d, i]) - digamma(np.sum(self.gamma[d])) )\n",
        "        for n in range(len(self.docs[d])):\n",
        "          elbo -= self.phi[d, n, i] * np.log(self.phi[d, n, i])\n",
        "\n",
        "    return elbo\n",
        "\n",
        "  def compute_perplexity(self, elbo):\n",
        "    # 분모\n",
        "    N = sum(len(doc) for doc in self.docs)\n",
        "\n",
        "    perplexity = np.exp(-elbo / N)\n",
        "    return perplexity\n",
        "\n",
        "  def run(self):\n",
        "    start_time = time.time()\n",
        "    print(\"EM Algorithm 시작!\")\n",
        "\n",
        "    ## Run the variational inference algorithm\n",
        "    for iter in range(self.num_iter):\n",
        "      print(f\"=== Iteration: {iter + 1} ===\")\n",
        "      print(f\"start time: {round(time.time() - start_time, 2)}\")\n",
        "      self.e_step()\n",
        "      self.m_step()\n",
        "\n",
        "      elbo = self.compute_elbo()\n",
        "      print(f\"ELBO: {elbo}\")\n",
        "      perplexity = self.compute_perplexity(elbo)\n",
        "      print(f\"Perplexity: {perplexity}\")\n",
        "\n",
        "      print()\n",
        "\n",
        "    print(\"EM Algorithm 끝!\")"
      ],
      "metadata": {
        "id": "Iu7yyF62usdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Run!!**"
      ],
      "metadata": {
        "id": "2EDzPY7kwXkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LDA_VI(train_data_idx,num_topic = 10, vocab = v_t_i, alpha = 1.,num_iter = 100,lr = 1e-3)\n",
        "model.run()"
      ],
      "metadata": {
        "id": "zNeY3GcVwdap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "56b2d239-6874-4264-cf3d-5207bc06cf93"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-29-3cf0da254ee6>:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self.beta[k][v] += np.random.rand(1) * 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "EM Algorithm 시작!\n",
            "=== Iteration: 1 ===\n",
            "start time: 0.0\n",
            "ELBO: -13567.009199459579\n",
            "Perplexity: 1.4980510371416667\n",
            "\n",
            "=== Iteration: 2 ===\n",
            "start time: 9.18\n",
            "ELBO: -180201.51893353215\n",
            "Perplexity: 214.4878442112404\n",
            "\n",
            "=== Iteration: 3 ===\n",
            "start time: 16.48\n",
            "ELBO: -178161.7247086239\n",
            "Perplexity: 201.8423672371536\n",
            "\n",
            "=== Iteration: 4 ===\n",
            "start time: 25.66\n",
            "ELBO: -177031.22805220686\n",
            "Perplexity: 195.15794881618368\n",
            "\n",
            "=== Iteration: 5 ===\n",
            "start time: 34.18\n",
            "ELBO: -176321.32710088676\n",
            "Perplexity: 191.07405569082096\n",
            "\n",
            "=== Iteration: 6 ===\n",
            "start time: 41.99\n",
            "ELBO: -175831.57419488177\n",
            "Perplexity: 188.3065470982896\n",
            "\n",
            "=== Iteration: 7 ===\n",
            "start time: 51.2\n",
            "ELBO: -175480.20275508176\n",
            "Perplexity: 186.3457375368859\n",
            "\n",
            "=== Iteration: 8 ===\n",
            "start time: 58.51\n",
            "ELBO: -175229.31011513976\n",
            "Perplexity: 184.95815145400383\n",
            "\n",
            "=== Iteration: 9 ===\n",
            "start time: 67.72\n",
            "ELBO: -175054.00923558066\n",
            "Perplexity: 183.99476929640215\n",
            "\n",
            "=== Iteration: 10 ===\n",
            "start time: 75.78\n",
            "ELBO: -174932.9992215256\n",
            "Perplexity: 183.3326766596598\n",
            "\n",
            "=== Iteration: 11 ===\n",
            "start time: 84.31\n",
            "ELBO: -174849.09794899996\n",
            "Perplexity: 182.8750194308248\n",
            "\n",
            "=== Iteration: 12 ===\n",
            "start time: 93.25\n",
            "ELBO: -174790.13091718662\n",
            "Perplexity: 182.55405508499894\n",
            "\n",
            "=== Iteration: 13 ===\n",
            "start time: 100.5\n",
            "ELBO: -174747.94518054088\n",
            "Perplexity: 182.32477898312027\n",
            "\n",
            "=== Iteration: 14 ===\n",
            "start time: 109.63\n",
            "ELBO: -174717.1308486508\n",
            "Perplexity: 182.15748756360267\n",
            "\n",
            "=== Iteration: 15 ===\n",
            "start time: 117.26\n",
            "ELBO: -174694.10906443076\n",
            "Perplexity: 182.03260217673946\n",
            "\n",
            "=== Iteration: 16 ===\n",
            "start time: 125.87\n",
            "ELBO: -174676.51447414316\n",
            "Perplexity: 181.93721520600423\n",
            "\n",
            "=== Iteration: 17 ===\n",
            "start time: 134.87\n",
            "ELBO: -174662.77453445262\n",
            "Perplexity: 181.8627605221366\n",
            "\n",
            "=== Iteration: 18 ===\n",
            "start time: 142.13\n",
            "ELBO: -174651.83036115565\n",
            "Perplexity: 181.80347748031537\n",
            "\n",
            "=== Iteration: 19 ===\n",
            "start time: 151.16\n",
            "ELBO: -174642.956579828\n",
            "Perplexity: 181.75542364676062\n",
            "\n",
            "=== Iteration: 20 ===\n",
            "start time: 158.46\n",
            "ELBO: -174635.64662679855\n",
            "Perplexity: 181.7158478913985\n",
            "\n",
            "=== Iteration: 21 ===\n",
            "start time: 167.64\n",
            "ELBO: -174629.5397219227\n",
            "Perplexity: 181.6827919911413\n",
            "\n",
            "=== Iteration: 22 ===\n",
            "start time: 176.02\n",
            "ELBO: -174624.37395565715\n",
            "Perplexity: 181.65483504921667\n",
            "\n",
            "=== Iteration: 23 ===\n",
            "start time: 184.06\n",
            "ELBO: -174619.95572393446\n",
            "Perplexity: 181.63092715067276\n",
            "\n",
            "=== Iteration: 24 ===\n",
            "start time: 193.23\n",
            "ELBO: -174616.13948348534\n",
            "Perplexity: 181.61027927496886\n",
            "\n",
            "=== Iteration: 25 ===\n",
            "start time: 200.43\n",
            "ELBO: -174612.8141085201\n",
            "Perplexity: 181.59228915450637\n",
            "\n",
            "=== Iteration: 26 ===\n",
            "start time: 209.53\n",
            "ELBO: -174609.89352771087\n",
            "Perplexity: 181.57649042107752\n",
            "\n",
            "=== Iteration: 27 ===\n",
            "start time: 217.03\n",
            "ELBO: -174607.31019799056\n",
            "Perplexity: 181.56251717586687\n",
            "\n",
            "=== Iteration: 28 ===\n",
            "start time: 225.85\n",
            "ELBO: -174605.0104737018\n",
            "Perplexity: 181.55007885877438\n",
            "\n",
            "=== Iteration: 29 ===\n",
            "start time: 234.88\n",
            "ELBO: -174602.9512752059\n",
            "Perplexity: 181.53894217553798\n",
            "\n",
            "=== Iteration: 30 ===\n",
            "start time: 242.02\n",
            "ELBO: -174601.0976547204\n",
            "Perplexity: 181.5289178961217\n",
            "\n",
            "=== Iteration: 31 ===\n",
            "start time: 250.97\n",
            "ELBO: -174599.42099601548\n",
            "Perplexity: 181.5198510932334\n",
            "\n",
            "=== Iteration: 32 ===\n",
            "start time: 258.22\n",
            "ELBO: -174597.89766473472\n",
            "Perplexity: 181.51161382580136\n",
            "\n",
            "=== Iteration: 33 ===\n",
            "start time: 267.33\n",
            "ELBO: -174596.50798514267\n",
            "Perplexity: 181.50409959307282\n",
            "\n",
            "=== Iteration: 34 ===\n",
            "start time: 275.64\n",
            "ELBO: -174595.23545683068\n",
            "Perplexity: 181.49721908998575\n",
            "\n",
            "=== Iteration: 35 ===\n",
            "start time: 283.58\n",
            "ELBO: -174594.06614638586\n",
            "Perplexity: 181.4908969111943\n",
            "\n",
            "=== Iteration: 36 ===\n",
            "start time: 292.76\n",
            "ELBO: -174592.9882137271\n",
            "Perplexity: 181.48506898507495\n",
            "\n",
            "=== Iteration: 37 ===\n",
            "start time: 299.93\n",
            "ELBO: -174591.9915377726\n",
            "Perplexity: 181.47968054611277\n",
            "\n",
            "=== Iteration: 38 ===\n",
            "start time: 308.91\n",
            "ELBO: -174591.0674189651\n",
            "Perplexity: 181.47468452378493\n",
            "\n",
            "=== Iteration: 39 ===\n",
            "start time: 316.19\n",
            "ELBO: -174590.20834085663\n",
            "Perplexity: 181.47004025144784\n",
            "\n",
            "=== Iteration: 40 ===\n",
            "start time: 325.17\n",
            "ELBO: -174589.40777773212\n",
            "Perplexity: 181.46571242464634\n",
            "\n",
            "=== Iteration: 41 ===\n",
            "start time: 334.02\n",
            "ELBO: -174588.6600387532\n",
            "Perplexity: 181.4616702572468\n",
            "\n",
            "=== Iteration: 42 ===\n",
            "start time: 341.5\n",
            "ELBO: -174587.96013826627\n",
            "Perplexity: 181.45788677931128\n",
            "\n",
            "=== Iteration: 43 ===\n",
            "start time: 350.53\n",
            "ELBO: -174587.30369281417\n",
            "Perplexity: 181.4543382795548\n",
            "\n",
            "=== Iteration: 44 ===\n",
            "start time: 357.65\n",
            "ELBO: -174586.68683279047\n",
            "Perplexity: 181.45100382713096\n",
            "\n",
            "=== Iteration: 45 ===\n",
            "start time: 366.75\n",
            "ELBO: -174586.10612959464\n",
            "Perplexity: 181.4478648773453\n",
            "\n",
            "=== Iteration: 46 ===\n",
            "start time: 374.56\n",
            "ELBO: -174585.55853585564\n",
            "Perplexity: 181.44490494811686\n",
            "\n",
            "=== Iteration: 47 ===\n",
            "start time: 382.95\n",
            "ELBO: -174585.0413340921\n",
            "Perplexity: 181.4421093421267\n",
            "\n",
            "=== Iteration: 48 ===\n",
            "start time: 391.97\n",
            "ELBO: -174584.55209279287\n",
            "Perplexity: 181.4394649091423\n",
            "\n",
            "=== Iteration: 49 ===\n",
            "start time: 399.1\n",
            "ELBO: -174584.08863118163\n",
            "Perplexity: 181.43695985533353\n",
            "\n",
            "=== Iteration: 50 ===\n",
            "start time: 408.22\n",
            "ELBO: -174583.64898769822\n",
            "Perplexity: 181.4345835727225\n",
            "\n",
            "=== Iteration: 51 ===\n",
            "start time: 415.42\n",
            "ELBO: -174583.2313926726\n",
            "Perplexity: 181.4323264913264\n",
            "\n",
            "=== Iteration: 52 ===\n",
            "start time: 424.48\n",
            "ELBO: -174582.83424605257\n",
            "Perplexity: 181.430179958647\n",
            "\n",
            "=== Iteration: 53 ===\n",
            "start time: 432.81\n",
            "ELBO: -174582.45609821082\n",
            "Perplexity: 181.42813613582328\n",
            "\n",
            "=== Iteration: 54 ===\n",
            "start time: 440.64\n",
            "ELBO: -174582.09563156613\n",
            "Perplexity: 181.42618789820568\n",
            "\n",
            "=== Iteration: 55 ===\n",
            "start time: 449.61\n",
            "ELBO: -174581.75164720966\n",
            "Perplexity: 181.42432876299554\n",
            "\n",
            "=== Iteration: 56 ===\n",
            "start time: 456.73\n",
            "ELBO: -174581.42305098582\n",
            "Perplexity: 181.42255281395003\n",
            "\n",
            "=== Iteration: 57 ===\n",
            "start time: 465.75\n",
            "ELBO: -174581.10884290855\n",
            "Perplexity: 181.42085464412443\n",
            "\n",
            "=== Iteration: 58 ===\n",
            "start time: 473.05\n",
            "ELBO: -174580.8081073206\n",
            "Perplexity: 181.41922930263894\n",
            "\n",
            "=== Iteration: 59 ===\n",
            "start time: 482.03\n",
            "ELBO: -174580.5200041087\n",
            "Perplexity: 181.41767224715844\n",
            "\n",
            "=== Iteration: 60 ===\n",
            "start time: 490.93\n",
            "ELBO: -174580.24376057327\n",
            "Perplexity: 181.41617929991824\n",
            "\n",
            "=== Iteration: 61 ===\n",
            "start time: 498.47\n",
            "ELBO: -174579.97866611063\n",
            "Perplexity: 181.4147466189521\n",
            "\n",
            "=== Iteration: 62 ===\n",
            "start time: 507.55\n",
            "ELBO: -174579.72406446957\n",
            "Perplexity: 181.41337065621858\n",
            "\n",
            "=== Iteration: 63 ===\n",
            "start time: 514.8\n",
            "ELBO: -174579.47935091503\n",
            "Perplexity: 181.41204814224824\n",
            "\n",
            "=== Iteration: 64 ===\n",
            "start time: 524.0\n",
            "ELBO: -174579.24396455017\n",
            "Perplexity: 181.41077604463038\n",
            "\n",
            "=== Iteration: 65 ===\n",
            "start time: 532.06\n",
            "ELBO: -174579.0173867827\n",
            "Perplexity: 181.40955155970704\n",
            "\n",
            "=== Iteration: 66 ===\n",
            "start time: 540.57\n",
            "ELBO: -174578.79913595348\n",
            "Perplexity: 181.40837208352892\n",
            "\n",
            "=== Iteration: 67 ===\n",
            "start time: 551.64\n",
            "ELBO: -174578.5887654593\n",
            "Perplexity: 181.40723520169811\n",
            "\n",
            "=== Iteration: 68 ===\n",
            "start time: 558.89\n",
            "ELBO: -174578.3858587009\n",
            "Perplexity: 181.4061386620531\n",
            "\n",
            "=== Iteration: 69 ===\n",
            "start time: 568.05\n",
            "ELBO: -174578.1900292161\n",
            "Perplexity: 181.40508037537973\n",
            "\n",
            "=== Iteration: 70 ===\n",
            "start time: 575.55\n",
            "ELBO: -174578.00091511465\n",
            "Perplexity: 181.40405838532564\n",
            "\n",
            "=== Iteration: 71 ===\n",
            "start time: 584.27\n",
            "ELBO: -174577.8181801995\n",
            "Perplexity: 181.4030708744525\n",
            "\n",
            "=== Iteration: 72 ===\n",
            "start time: 593.16\n",
            "ELBO: -174577.6415082874\n",
            "Perplexity: 181.40211613353696\n",
            "\n",
            "=== Iteration: 73 ===\n",
            "start time: 600.3\n",
            "ELBO: -174577.4706057114\n",
            "Perplexity: 181.40119257508772\n",
            "\n",
            "=== Iteration: 74 ===\n",
            "start time: 609.25\n",
            "ELBO: -174577.30519582628\n",
            "Perplexity: 181.40029870364776\n",
            "\n",
            "=== Iteration: 75 ===\n",
            "start time: 616.5\n",
            "ELBO: -174577.1450201383\n",
            "Perplexity: 181.39943312189368\n",
            "\n",
            "=== Iteration: 76 ===\n",
            "start time: 625.56\n",
            "ELBO: -174576.98983564635\n",
            "Perplexity: 181.3985945162634\n",
            "\n",
            "=== Iteration: 77 ===\n",
            "start time: 633.77\n",
            "ELBO: -174576.83941406675\n",
            "Perplexity: 181.39778165276277\n",
            "\n",
            "=== Iteration: 78 ===\n",
            "start time: 641.82\n",
            "ELBO: -174576.6935412145\n",
            "Perplexity: 181.39699337361884\n",
            "\n",
            "=== Iteration: 79 ===\n",
            "start time: 650.77\n",
            "ELBO: -174576.55201490622\n",
            "Perplexity: 181.39622858594342\n",
            "\n",
            "=== Iteration: 80 ===\n",
            "start time: 657.92\n",
            "ELBO: -174576.41464504873\n",
            "Perplexity: 181.39548626221\n",
            "\n",
            "=== Iteration: 81 ===\n",
            "start time: 666.95\n",
            "ELBO: -174576.28125232062\n",
            "Perplexity: 181.39476543312563\n",
            "\n",
            "=== Iteration: 82 ===\n",
            "start time: 674.44\n",
            "ELBO: -174576.15166766354\n",
            "Perplexity: 181.3940651848802\n",
            "\n",
            "=== Iteration: 83 ===\n",
            "start time: 683.19\n",
            "ELBO: -174576.0257312016\n",
            "Perplexity: 181.3933846533045\n",
            "\n",
            "=== Iteration: 84 ===\n",
            "start time: 692.04\n",
            "ELBO: -174575.90329187975\n",
            "Perplexity: 181.3927230219143\n",
            "\n",
            "=== Iteration: 85 ===\n",
            "start time: 699.29\n",
            "ELBO: -174575.7842069791\n",
            "Perplexity: 181.3920795192903\n",
            "\n",
            "=== Iteration: 86 ===\n",
            "start time: 708.37\n",
            "ELBO: -174575.66834124152\n",
            "Perplexity: 181.3914534143447\n",
            "\n",
            "=== Iteration: 87 ===\n",
            "start time: 715.69\n",
            "ELBO: -174575.5555667083\n",
            "Perplexity: 181.39084401544912\n",
            "\n",
            "=== Iteration: 88 ===\n",
            "start time: 724.95\n",
            "ELBO: -174575.44576217668\n",
            "Perplexity: 181.3902506674961\n",
            "\n",
            "=== Iteration: 89 ===\n",
            "start time: 733.32\n",
            "ELBO: -174575.3388120995\n",
            "Perplexity: 181.38967274595166\n",
            "\n",
            "=== Iteration: 90 ===\n",
            "start time: 741.28\n",
            "ELBO: -174575.23460762683\n",
            "Perplexity: 181.38910966248343\n",
            "\n",
            "=== Iteration: 91 ===\n",
            "start time: 750.28\n",
            "ELBO: -174575.13304461568\n",
            "Perplexity: 181.38856085420485\n",
            "\n",
            "=== Iteration: 92 ===\n",
            "start time: 757.64\n",
            "ELBO: -174575.034024601\n",
            "Perplexity: 181.38802578892037\n",
            "\n",
            "=== Iteration: 93 ===\n",
            "start time: 766.81\n",
            "ELBO: -174574.93745392506\n",
            "Perplexity: 181.38750396042113\n",
            "\n",
            "=== Iteration: 94 ===\n",
            "start time: 774.53\n",
            "ELBO: -174574.84324306308\n",
            "Perplexity: 181.3869948848397\n",
            "\n",
            "=== Iteration: 95 ===\n",
            "start time: 783.21\n",
            "ELBO: -174574.7513070345\n",
            "Perplexity: 181.3864981028714\n",
            "\n",
            "=== Iteration: 96 ===\n",
            "start time: 792.26\n",
            "ELBO: -174574.66156485715\n",
            "Perplexity: 181.38601317682506\n",
            "\n",
            "=== Iteration: 97 ===\n",
            "start time: 799.52\n",
            "ELBO: -174574.5739395096\n",
            "Perplexity: 181.38553969041845\n",
            "\n",
            "=== Iteration: 98 ===\n",
            "start time: 808.6\n",
            "ELBO: -174574.48835706338\n",
            "Perplexity: 181.38507724408836\n",
            "\n",
            "=== Iteration: 99 ===\n",
            "start time: 815.75\n",
            "ELBO: -174574.40474753577\n",
            "Perplexity: 181.38462545959908\n",
            "\n",
            "=== Iteration: 100 ===\n",
            "start time: 824.93\n",
            "ELBO: -174574.32304346847\n",
            "Perplexity: 181.3841839723609\n",
            "\n",
            "EM Algorithm 끝!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ELBO 시각화\n",
        "\n"
      ],
      "metadata": {
        "id": "4MY20Yppt6eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Inference**"
      ],
      "metadata": {
        "id": "0fdKo5ISwdiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## analyze each doc's topic proportion\n",
        "\n",
        "for d, gamma in enumerate(model.gamma):\n",
        "  print(f\"Document {d} topic distribution: {gamma / np.sum(gamma)}\")"
      ],
      "metadata": {
        "id": "QJkH7f5FwhgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## analyze topic-word proportion\n",
        "\n",
        "for k, beta in enumerate(model.beta):\n",
        "  top_words = np.argsort(beta)[-10:]\n",
        "  print(f\"Topic {k} top words: {[i_t_v[i] for i in top_words]}\")"
      ],
      "metadata": {
        "id": "xgGQajygwizk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}
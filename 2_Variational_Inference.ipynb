{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMwYS8OFpCtT96KRLvMkpXz",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chasubeen/ML_lab/blob/main/2_Variational_Inference_1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        "from collections import defaultdict\n",
        "from scipy.special import digamma, polygamma, loggamma"
      ],
      "metadata": {
        "id": "SpkcsGAvAsYi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Preprocessing**"
      ],
      "metadata": {
        "id": "badhYe8TjrpX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1-1. Load data**"
      ],
      "metadata": {
        "id": "_Gx_9utFkNiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cUa6BHK3j0_6",
        "outputId": "e9ef6b16-792c-494b-8015-899d9306a243"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data path\n",
        "\n",
        "train_path = \"/content/drive/MyDrive/ML_lab/2_LDA/data/pos_tag/train.txt\"\n",
        "test_path = \"/content/drive/MyDrive/ML_lab/2_LDA/data/pos_tag/test.txt\""
      ],
      "metadata": {
        "id": "TfZ8ZwHjjw6t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_file(path):\n",
        "  raw = open(path, 'r').read().split('\\n') # 파일을 읽어와 줄마다 나누기\n",
        "  data, doc = list(), list()\n",
        "\n",
        "  for i, line in enumerate(raw):\n",
        "    if line.strip(): # 빈 줄이 아니면\n",
        "      word = line.split(' ')[0].lower() # 첫 번째 단어를 얻어온 후 소문자로 변환\n",
        "      doc.append(word)\n",
        "    else:\n",
        "      data.append(doc) # EOD(End Of Document)\n",
        "      doc = list()\n",
        "  data.append(doc) # 맨 마지막 문서 추가\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "rbh73TnykXzf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 불러오기\n",
        "train_data = read_file(train_path)\n",
        "test_data = read_file(test_path)\n",
        "\n",
        "# 맨 마지막 문서는 제거\n",
        "del train_data[-1], test_data[-1]"
      ],
      "metadata": {
        "id": "PrbMLqzHkn_y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1-2. Preprocess Data**"
      ],
      "metadata": {
        "id": "gPInqBrgmRB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# some words that we do not want to consider\n",
        "stopwords = [\"\",\" \"]"
      ],
      "metadata": {
        "id": "HG_s50dnmZnF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## remove numbers, special characters, etc.\n",
        "# only consider words with alphabet\n",
        "\n",
        "def only_alphabet(corpus,stopword_list = stopwords):\n",
        "  data = list()\n",
        "  for doc in corpus:\n",
        "    temp = list()\n",
        "    for word in doc:\n",
        "      word = re.sub('[^a-z]', '', word) # non-alphabet 문자 제거(=> 정규표현식 활용)\n",
        "      if word not in stopwords:\n",
        "        temp.append(word)\n",
        "    data.append(temp)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "bJcrZC1XmeAx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = only_alphabet(train_data)\n",
        "test_data = only_alphabet(test_data)"
      ],
      "metadata": {
        "id": "6Cgy8v8ompb8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## count word occurrence in corpus\n",
        "\n",
        "def count_vocab(corpus):\n",
        "  vocab = defaultdict(int) # dictionary 형태로 word occurence를 기록\n",
        "  for doc in corpus:\n",
        "    for word in doc:\n",
        "      vocab[word] += 1\n",
        "\n",
        "  return vocab"
      ],
      "metadata": {
        "id": "vTT8x1YImv8S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_count = count_vocab(train_data)"
      ],
      "metadata": {
        "id": "7y76zEHArmov"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## 특정 빈도수 이상인 단어들만 고려\n",
        "# sparse한 단어는 무시\n",
        "\n",
        "def vocab_top(vocab,cnt):\n",
        "  temp = defaultdict(int)\n",
        "  for voca, count in vocab.items():\n",
        "    if count > cnt:\n",
        "      temp[voca] = count\n",
        "\n",
        "  return temp"
      ],
      "metadata": {
        "id": "ggNlOiM1rqgE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_count = vocab_top(vocab_count,cnt = 5)"
      ],
      "metadata": {
        "id": "Biqdzl-8sbsi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## filter out low-occurrence words\n",
        "\n",
        "def filter_vocab(corpus,vocab):\n",
        "  data = list()\n",
        "  for doc in corpus:\n",
        "    temp = list()\n",
        "    for word in doc:\n",
        "      if word in vocab.keys():\n",
        "        temp.append(word)\n",
        "    if temp:\n",
        "      data.append(temp)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "QKFK8zuwsg9t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = filter_vocab(train_data,vocab_count)\n",
        "test_data = filter_vocab(test_data,vocab_count)"
      ],
      "metadata": {
        "id": "d1PgDw-Ds5OL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## construct voca-index-matching dictionary\n",
        "\n",
        "def voca_index(vocab):\n",
        "  vocab_to_index, index_to_vocab = dict(), dict()\n",
        "  for i, voca in enumerate(vocab.keys()):\n",
        "    vocab_to_index[voca] = i\n",
        "    index_to_vocab[i] = voca\n",
        "\n",
        "  return vocab_to_index, index_to_vocab"
      ],
      "metadata": {
        "id": "pl9QYCl0s82P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "v_t_i, i_t_v = voca_index(vocab_count)"
      ],
      "metadata": {
        "id": "4nJ2IzIttOtX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## convert corpus-with-words to corpus-with-index\n",
        "\n",
        "def corpus_to_index(corpus,vocab_to_index):\n",
        "  data = list()\n",
        "  for doc in corpus:\n",
        "    temp = list()\n",
        "    for word in doc:\n",
        "      temp.append(vocab_to_index[word])\n",
        "    data.append(temp)\n",
        "\n",
        "  return data"
      ],
      "metadata": {
        "id": "bbbnUBVQtRba"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_idx = corpus_to_index(train_data,v_t_i)\n",
        "test_data_idx = corpus_to_index(test_data,v_t_i)"
      ],
      "metadata": {
        "id": "ZlpCKhKvuR9j"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Modeling**"
      ],
      "metadata": {
        "id": "JLLADECRuh36"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class LDA_VI:\n",
        "  def __init__(self,docs, num_topic=10, vocab = None, alpha=1.,num_iter=100,lr=1e-3):\n",
        "    self.docs = docs\n",
        "    self.num_topic = num_topic\n",
        "    self.vocab = vocab\n",
        "    self.num_vocab = len(self.vocab)\n",
        "    self.num_docs = len(self.docs)\n",
        "\n",
        "    # Initialize alpha and beta\n",
        "    self.alpha = np.ones(self.num_topic)*(1/self.num_topic)\n",
        "    self.beta = np.ones((self.num_topic, self.num_vocab))*(1/self.num_vocab)\n",
        "    # beta 초기값 업데이트\n",
        "    for i in range(self.num_topic):\n",
        "      for v in range(self.num_vocab):\n",
        "        self.beta[i][v] += np.random.rand(1) * 0.01\n",
        "    # beta normailize 진행\n",
        "    for i in range(self.num_topic):\n",
        "      self.beta[i] /= np.sum(self.beta[i])\n",
        "\n",
        "    # Initialize gamma and phi\n",
        "    self.gamma = np.ones((self.num_docs,self.num_topic))*(1/self.num_topic)\n",
        "    self.phi = np.ones((self.num_docs, self.num_topic,self.num_vocab))*(1/self.num_vocab)\n",
        "\n",
        "    # Initialize z (topic assignments for words in documents)\n",
        "    self.z = list()\n",
        "    for doc in self.docs:\n",
        "      temp = list()\n",
        "      for word in doc:\n",
        "        temp.append(None)\n",
        "      self.z.append(temp)\n",
        "\n",
        "    # Initialize parameters for variational inference\n",
        "    self.num_iter = num_iter\n",
        "    self.lr = lr\n",
        "\n",
        "  def update_gamma(self):\n",
        "    ## Update gamma (document-topic distributions)\n",
        "    # d: document의 index\n",
        "    for d in range(self.num_docs):\n",
        "      for k in range(self.num_topic):\n",
        "        self.gamma[d, k] = self.alpha[k] + np.sum(self.phi[d, k])\n",
        "\n",
        "  def update_phi(self):\n",
        "    ## Update phi (topic-word distributions)\n",
        "    for d in range(self.num_docs):\n",
        "      for n in range(len(self.docs[d])):\n",
        "        for k in range(self.num_topic):\n",
        "          self.phi[d, k, n] = self.beta[k, self.docs[d][n]] * np.exp(digamma(self.gamma[d, k]))\n",
        "        # phi 정규화\n",
        "        self.phi[d, :, n] /= np.sum(self.phi[d, :, n])\n",
        "\n",
        "  def update_beta(self):\n",
        "    ## Update beta(topic-word prior)\n",
        "    for k in range(self.num_topic):\n",
        "      for v in range(self.num_vocab):\n",
        "        for d in range(self.num_docs):\n",
        "          for n in range(len(self.docs[d])):\n",
        "            if self.docs[d][n] == v:\n",
        "              self.beta[k, v] += self.phi[d, k, n]\n",
        "      # beta 정규화\n",
        "      self.beta[k] /= np.sum(self.beta[k])\n",
        "\n",
        "  def update_alpha(self):\n",
        "    ## Update alpha(document-topic prior)\n",
        "    M = self.num_docs\n",
        "    g = np.zeros(self.num_topic) # gradient\n",
        "    H = np.zeros((self.num_topic, self.num_topic)) # Hessian matrix\n",
        "\n",
        "    for i in range(self.num_topic):\n",
        "      g[i] = M * ( digamma(np.sum(self.alpha)) - digamma(self.alpha[i]) )\n",
        "      for d in range(M):\n",
        "        g[i] += ( digamma(self.gamma[d, i]) - digamma(np.sum(self.gamma[d, :])) )\n",
        "      for j in range(self.num_topic):\n",
        "        H[i, j] = 0\n",
        "        if i == j:\n",
        "          H[i, j] = -M * polygamma(1, self.alpha[i])\n",
        "\n",
        "\n",
        "    # alpha 업데이트(=> Newton-Raphson)\n",
        "    deltaAlpha = np.dot(np.linalg.inv(H), g)\n",
        "\n",
        "    for k in range(self.num_topic):\n",
        "      self.alpha[k] -= deltaAlpha[k]\n",
        "\n",
        "  def e_step(self):\n",
        "    ## Perform E-step of the variational inference\n",
        "    self.update_phi()\n",
        "    self.update_gamma()\n",
        "\n",
        "  def m_step(self):\n",
        "    ## Perform M-step of the variational inference\n",
        "    self.update_beta()\n",
        "    self.update_alpha()\n",
        "\n",
        "  def compute_elbo(self):\n",
        "    ## Compute Evidence Lower Bound (ELBO)\n",
        "\n",
        "    # 필요한 파라미터 정의\n",
        "    elbo = 0\n",
        "    M = self.num_docs\n",
        "    k = self.num_topic\n",
        "\n",
        "    # 1번 수식\n",
        "    for d in range(M): # document\n",
        "      for n in range(len(self.docs[d])):\n",
        "        j = self.docs[d][n] # word idx\n",
        "        for i in range(k): # topic\n",
        "          elbo += self.phi[d, i, n] * np.log(self.beta[i, j])\n",
        "\n",
        "    # 2번 수식\n",
        "    for d in range(M):\n",
        "      for n in range(len(self.docs[d])):\n",
        "        for i in range(k):\n",
        "          elbo += self.phi[d, i, n] * (digamma(self.gamma[d, i]) - digamma(np.sum(self.gamma[d, :])))\n",
        "\n",
        "    # 3번 수식\n",
        "    elbo += M * (loggamma(np.sum(self.alpha)) - np.sum(loggamma(self.alpha)))\n",
        "\n",
        "    for d in range(M):\n",
        "      for i in range(k):\n",
        "        elbo += (self.alpha[i] - 1) * (digamma(self.gamma[d, i]) - digamma(np.sum(self.gamma[d, :])))\n",
        "\n",
        "    # 4번 수식\n",
        "    for d in range(M):\n",
        "      for i in range(k):\n",
        "        elbo -= (self.gamma[d, i] - 1) * (digamma(self.gamma[d, i]) - digamma(np.sum(self.gamma[d, :])))\n",
        "\n",
        "    for d in range(M):\n",
        "      elbo -= loggamma(np.sum(self.gamma[d, :])) - np.sum(loggamma(self.gamma[d, :]))\n",
        "\n",
        "    # 5번 수식\n",
        "    for d in range(M):\n",
        "      for n in range(len(self.docs[d])):\n",
        "        for i in range(k):\n",
        "          elbo -= self.phi[d, i, n] * np.log(self.phi[d, i, n])\n",
        "\n",
        "    return elbo\n",
        "\n",
        "  def compute_perplexity(self, elbo):\n",
        "    # 분모\n",
        "    N = sum(len(doc) for doc in self.docs)\n",
        "\n",
        "    perplexity = np.exp(-elbo / N)\n",
        "    return perplexity\n",
        "\n",
        "  def run(self):\n",
        "    ## Run the variational inference algorithm\n",
        "    for iter in range(self.num_iter):\n",
        "      print(f\"=== Iteration: {iter} ===\")\n",
        "      self.e_step()\n",
        "      self.m_step()\n",
        "      print(f\"Alpha: {self.alpha}\")\n",
        "\n",
        "      elbo = self.compute_elbo()\n",
        "      print(f\"ELBO: {elbo}\")\n",
        "      perplexity = self.compute_perplexity(elbo)\n",
        "      print(f\"Perplexity: {perplexity}\")\n",
        "\n",
        "    print(\"EM Algorithm 끝!\")"
      ],
      "metadata": {
        "id": "Iu7yyF62usdk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Run!!**"
      ],
      "metadata": {
        "id": "2EDzPY7kwXkd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = LDA_VI(test_data_idx,num_topic = 10, vocab = v_t_i, alpha = 1.,num_iter = 50,lr = 1e-3)\n",
        "model.run()"
      ],
      "metadata": {
        "id": "zNeY3GcVwdap",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "22f70c1d-6f98-4b3a-c58b-b3852161cfee"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-19-d1147a38c77d>:15: DeprecationWarning: Conversion of an array with ndim > 0 to a scalar is deprecated, and will error in future. Ensure you extract a single element from your array before performing this operation. (Deprecated NumPy 1.25.)\n",
            "  self.beta[i][v] += np.random.rand(1) * 0.01\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "=== Iteration: 0 ===\n",
            "Alpha: [0.17279333 0.17228359 0.17252091 0.17245722 0.172115   0.17272764\n",
            " 0.17260403 0.1721599  0.17285073 0.17177484]\n",
            "ELBO: -235056.953146378\n",
            "Perplexity: 1099.281008685372\n",
            "=== Iteration: 1 ===\n",
            "Alpha: [0.28385037 0.28215863 0.28297113 0.28278656 0.28162609 0.28362013\n",
            " 0.28324008 0.28179221 0.28403409 0.28056687]\n",
            "ELBO: -228605.70247866696\n",
            "Perplexity: 907.0767586957061\n",
            "=== Iteration: 2 ===\n",
            "Alpha: [0.43749975 0.43388356 0.43566916 0.43532114 0.43275744 0.43691895\n",
            " 0.43617032 0.43311106 0.43782767 0.43064685]\n",
            "ELBO: -223708.92860575503\n",
            "Perplexity: 783.9543787921336\n",
            "=== Iteration: 3 ===\n",
            "Alpha: [0.62796885 0.62226129 0.62515137 0.62464099 0.62035521 0.62676281\n",
            " 0.62566491 0.62081973 0.62828803 0.61732632]\n",
            "ELBO: -220133.6393700775\n",
            "Perplexity: 704.7491850373685\n",
            "=== Iteration: 4 ===\n",
            "Alpha: [0.84134336 0.83428366 0.83794163 0.83729579 0.83139349 0.83921965\n",
            " 0.83788237 0.83169124 0.84135693 0.8282353 ]\n",
            "ELBO: -217563.1940924874\n",
            "Perplexity: 652.7979727520324\n",
            "=== Iteration: 5 ===\n",
            "Alpha: [1.06303076 1.05572777 1.05959887 1.05887676 1.05147688 1.05979201\n",
            " 1.05819471 1.05129676 1.06251755 1.04932112]\n",
            "ELBO: -215679.4054451181\n",
            "Perplexity: 617.1728395419331\n",
            "=== Iteration: 6 ===\n",
            "Alpha: [1.28256126 1.27585596 1.2795242  1.27888819 1.26970161 1.27816429\n",
            " 1.27602026 1.26890392 1.28153758 1.26965397]\n",
            "ELBO: -214238.46425545207\n",
            "Perplexity: 591.2406213085471\n",
            "=== Iteration: 7 ===\n",
            "Alpha: [1.49377939 1.48807315 1.49139553 1.49115976 1.47943989 1.48829958\n",
            " 1.48512032 1.47812125 1.49251459 1.48245299]\n",
            "ELBO: -213084.19859868387\n",
            "Perplexity: 571.255850758436\n",
            "=== Iteration: 8 ===\n",
            "Alpha: [1.69351309 1.68876111 1.69191018 1.69256724 1.67722607 1.68707986\n",
            " 1.68232748 1.6756954  1.69247269 1.68408148]\n",
            "ELBO: -212126.1987937133\n",
            "Perplexity: 555.1831754511086\n",
            "=== Iteration: 9 ===\n",
            "Alpha: [1.88046087 1.87612291 1.87964048 1.88188379 1.86162263 1.87325547\n",
            " 1.86643464 1.8603386  1.88019721 1.87291778]\n",
            "ELBO: -211315.1459923202\n",
            "Perplexity: 541.929878700714\n",
            "=== Iteration: 10 ===\n",
            "Alpha: [2.05447673 2.04958425 2.05432954 2.05901067 2.03246032 2.04678873\n",
            " 2.03745339 2.03196845 2.05550087 2.04860319]\n",
            "ELBO: -210624.07903539424\n",
            "Perplexity: 530.8871856591737\n",
            "=== Iteration: 11 ===\n",
            "Alpha: [2.21608706 2.20950684 2.21646049 2.22448496 2.19032921 2.20834876\n",
            " 2.19611432 2.19123432 2.21880142 2.21154945]\n",
            "ELBO: -210035.93148145714\n",
            "Perplexity: 521.6664839532674\n",
            "=== Iteration: 12 ===\n",
            "Alpha: [2.36615501 2.35690658 2.36693176 2.37915888 2.33623841 2.35891633\n",
            " 2.34350455 2.3391695  2.37089256 2.36260403]\n",
            "ELBO: -209536.95610059882\n",
            "Perplexity: 513.9694611152269\n",
            "=== Iteration: 13 ===\n",
            "Alpha: [2.50567251 2.4931107  2.50682691 2.52398951 2.47139275 2.49954065\n",
            " 2.48080117 2.47693868 2.51278515 2.50282042]\n",
            "ELBO: -209114.30221853338\n",
            "Perplexity: 507.5386539967709\n",
            "=== Iteration: 14 ===\n",
            "Alpha: [2.63564816 2.61946877 2.63727087 2.65990953 2.59704441 2.63123201\n",
            " 2.60912155 2.60568813 2.64555971 2.63328893]\n",
            "ELBO: -208755.9117308324\n",
            "Perplexity: 502.14871549190747\n",
            "=== Iteration: 15 ===\n",
            "Alpha: [2.75704485 2.73719755 2.75934431 2.78775754 2.71439625 2.75492604\n",
            " 2.72948354 2.72647216 2.77024578 2.75502795]\n",
            "ELBO: -208451.07330918076\n",
            "Perplexity: 497.60923531263734\n",
            "=== Iteration: 16 ===\n",
            "Alpha: [2.87075594 2.8473344  2.87404064 2.90825996 2.82454805 2.87146691\n",
            " 2.84280435 2.84021957 2.88774825 2.86893981]\n",
            "ELBO: -208190.6999253071\n",
            "Perplexity: 493.7644126062086\n",
            "=== Iteration: 17 ===\n",
            "Alpha: [2.97760493 2.95074815 2.98224851 3.02204726 2.92847299 2.98159521\n",
            " 2.9498955  2.94772198 2.99882668 2.97580713]\n",
            "ELBO: -207967.24521565184\n",
            "Perplexity: 490.4884485161474\n",
            "=== Iteration: 18 ===\n",
            "Alpha: [3.07834173 3.04817317 3.08474749 3.12968096 3.02700427 3.08594409\n",
            " 3.05145969 3.04964172 3.10411188 3.07630566]\n",
            "ELBO: -207774.48451725\n",
            "Perplexity: 487.6799418438067\n",
            "=== Iteration: 19 ===\n",
            "Alpha: [3.17363677 3.14024585 3.18221064 3.23167497 3.12082571 3.1850462\n",
            " 3.14809118 3.14653322 3.20413279 3.1710233 ]\n",
            "ELBO: -207607.2760029901\n",
            "Perplexity: 485.25675661619016\n",
            "=== Iteration: 20 ===\n",
            "Alpha: [3.26408068 3.22753202 3.27520846 3.32850595 3.21047616 3.27934761\n",
            " 3.24028158 3.23886695 3.29933755 3.26048208]\n",
            "ELBO: -207461.3687262199\n",
            "Perplexity: 483.15210817423184\n",
            "=== Iteration: 21 ===\n",
            "Alpha: [3.35018836 3.31054255 3.36421046 3.42061407 3.296371   3.36922425\n",
            " 3.32843805 3.32704822 3.39010994 3.34515843]\n",
            "ELBO: -207333.2770745228\n",
            "Perplexity: 481.31196806128725\n",
            "=== Iteration: 22 ===\n",
            "Alpha: [3.43240449 3.3897383  3.44958824 3.50839899 3.37883352 3.45500047\n",
            " 3.41290915 3.41142985 3.47678534 3.42549657]\n",
            "ELBO: -207220.1832734392\n",
            "Perplexity: 479.6931106017605\n",
            "=== Iteration: 23 ===\n",
            "Alpha: [3.5111094  3.46552649 3.53162575 3.59221627 3.45812574 3.53696663\n",
            " 3.494007   3.49232187 3.55966637 3.50191528]\n",
            "ELBO: -207119.8366824887\n",
            "Perplexity: 478.26127990305145\n",
            "=== Iteration: 24 ===\n",
            "Alpha: [3.58662479 3.53825435 3.61053859 3.67237826 3.53447122 3.61539148\n",
            " 3.57202013 3.56999964 3.63903464 3.57481146]\n",
            "ELBO: -207030.4450322114\n",
            "Perplexity: 476.98936348001195\n",
            "=== Iteration: 25 ===\n",
            "Alpha: [3.65921895 3.60820684 3.686498   3.74915974 3.60806822 3.69052874\n",
            " 3.64722092 3.64470968 3.71515543 3.64455676]\n",
            "ELBO: -206950.55374034142\n",
            "Perplexity: 475.8554864233228\n",
            "=== Iteration: 26 ===\n",
            "Alpha: [3.72911386 3.67560977 3.75965141 3.82280554 3.67909558 3.76262001\n",
            " 3.71987058 3.71667345 3.78827757 3.71148384]\n",
            "ELBO: -206878.9140464035\n",
            "Perplexity: 474.84101459732256\n",
            "=== Iteration: 27 ===\n",
            "Alpha: [3.79649488 3.74063524 3.83013615 3.89353628 3.74771561 3.83189467\n",
            " 3.79021535 3.78609075 3.85863305 3.77587721]\n",
            "ELBO: -206814.40862250116\n",
            "Perplexity: 473.9294199203732\n",
            "=== Iteration: 28 ===\n",
            "Alpha: [3.86152002 3.80341031 3.89808686 3.96155184 3.81407737 3.89856648\n",
            " 3.85847576 3.85314204 3.92643696 3.83797811]\n",
            "ELBO: -206756.05135391114\n",
            "Perplexity: 473.1062192643783\n",
            "=== Iteration: 29 ===\n",
            "Alpha: [3.92432475 3.86403173 3.96363875 4.02703366 3.87831978 3.96283026\n",
            " 3.92483881 3.91798775 3.99188722 3.89799465]\n",
            "ELBO: -206702.9969168358\n",
            "Perplexity: 472.359062480308\n",
            "=== Iteration: 30 ===\n",
            "Alpha: [3.98502345 3.92258418 4.02692818 4.09014687 3.94057089 4.02486303\n",
            " 3.9894556  3.98076592 4.05516394 3.95611076]\n",
            "ELBO: -206654.5416749835\n",
            "Perplexity: 471.67770639697693\n",
            "=== Iteration: 31 ===\n",
            "Alpha: [4.04371056 3.97916013 4.08809176 4.15104251 4.00094265 4.08482859\n",
            " 4.05244277 4.04159186 4.1164291  4.01249221]\n",
            "ELBO: -206610.1457364783\n",
            "Perplexity: 471.05429323888075\n",
            "=== Iteration: 32 ===\n",
            "Alpha: [4.10046611 4.03388171 4.14726507 4.20985976 4.05952863 4.14287935\n",
            " 4.11388655 4.10056197 4.17582669 4.06728846]\n",
            "ELBO: -206569.49022457807\n",
            "Perplexity: 470.4841263873479\n",
            "=== Iteration: 33 ===\n",
            "Alpha: [4.15537407 4.08689535 4.20458126 4.26672829 4.11640797 4.19915418\n",
            " 4.1738496  4.15776004 4.23348402 4.12063364]\n",
            "ELBO: -206532.37672466398\n",
            "Perplexity: 469.9642365118681\n",
            "=== Iteration: 34 ===\n",
            "Alpha: [4.20853611 4.13832478 4.26017024 4.32177126 4.17165144 4.25377559\n",
            " 4.23237894 4.21326335 4.28951405 4.17264905]\n",
            "ELBO: -206498.46069997316\n",
            "Perplexity: 469.4896396019004\n",
            "=== Iteration: 35 ===\n",
            "Alpha: [4.26005414 4.18825698 4.31415762 4.375109   4.22532621 4.30684769\n",
            " 4.28951271 4.26714659 4.34401777 4.22344301]\n",
            "ELBO: -206467.3163602092\n",
            "Perplexity: 469.0542498307036\n",
            "=== Iteration: 36 ===\n",
            "Alpha: [4.31001378 4.23676273 4.36666242 4.42686159 4.27749874 4.35845653\n",
            " 4.34528469 4.31948405 4.3970857  4.27310626]\n",
            "ELBO: -206438.605878217\n",
            "Perplexity: 468.65324243631767\n",
            "=== Iteration: 37 ===\n",
            "Alpha: [4.35848566 4.28390894 4.41779448 4.47714529 4.32823529 4.40867521\n",
            " 4.39972771 4.37035087 4.44879952 4.3217076 ]\n",
            "ELBO: -206412.0674466684\n",
            "Perplexity: 468.28287759790237\n",
            "=== Iteration: 38 ===\n",
            "Alpha: [4.40553208 4.32976038 4.46765299 4.52606307 4.37760036 4.45757037\n",
            " 4.45287562 4.41982329 4.49923371 4.36929478]\n",
            "ELBO: -206387.4597083601\n",
            "Perplexity: 467.9397186427239\n",
            "=== Iteration: 39 ===\n",
            "Alpha: [4.45121213 4.37437865 4.51632624 4.57369975 4.42565454 4.5052032\n",
            " 4.50476418 4.46797801 4.54845674 4.41589964]\n",
            "ELBO: -206364.55121485455\n",
            "Perplexity: 467.62048195975564\n",
            "=== Iteration: 40 ===\n",
            "Alpha: [4.49558427 4.41782155 4.56389176 4.62012494 4.47245339 4.55162689\n",
            " 4.55543074 4.51489146 4.59653166 4.46154419]\n",
            "ELBO: -206343.13808599894\n",
            "Perplexity: 467.3222805600958\n",
            "=== Iteration: 41 ===\n",
            "Alpha: [4.53870697 4.46014323 4.61041658 4.66539767 4.51804747 4.59688576\n",
            " 4.60491333 4.56063946 4.64351632 4.50624543]\n",
            "ELBO: -206323.05358453243\n",
            "Perplexity: 467.04275459252335\n",
            "=== Iteration: 42 ===\n",
            "Alpha: [4.58063839 4.50139458 4.65595751 4.70956934 4.56248291 4.64101725\n",
            " 4.65324934 4.60529723 4.6894635  4.5500188 ]\n",
            "ELBO: -206304.16517054554\n",
            "Perplexity: 466.78002772709425\n",
            "=== Iteration: 43 ===\n",
            "Alpha: [4.62143618 4.54162298 4.70056205 4.75268545 4.60580187 4.68405493\n",
            " 4.70047432 4.64893932 4.73442106 4.59288019]\n",
            "ELBO: -206286.36653507184\n",
            "Perplexity: 466.53259429714257\n",
            "=== Iteration: 44 ===\n",
            "Alpha: [4.66115749 4.58087132 4.74426946 4.794787   4.6480429  4.72603125\n",
            " 4.74662142 4.69163881 4.77843212 4.63484723]\n",
            "ELBO: -206269.5691838039\n",
            "Perplexity: 466.2992008419188\n",
            "=== Iteration: 45 ===\n",
            "Alpha: [4.69985876 4.61917732 4.78711234 4.83591199 4.68924122 4.76697929\n",
            " 4.79172174 4.73346563 4.821535   4.6759398 ]\n",
            "ELBO: -206253.6967134909\n",
            "Perplexity: 466.0787655863648\n",
            "=== Iteration: 46 ===\n",
            "Alpha: [4.73759508 4.65657407 4.8291182  4.87609726 4.72942936 4.80693343\n",
            " 4.83580589 4.77448362 4.86376293 4.71617983]\n",
            "ELBO: -206238.68261543725\n",
            "Perplexity: 465.87034722471856\n",
            "=== Iteration: 47 ===\n",
            "Alpha: [4.77441931 4.69309164 4.87031117 4.91538051 4.76863822 4.8459291\n",
            " 4.87890627 4.81474673 4.90514354 4.75559049]\n",
            "ELBO: -206224.4696164182\n",
            "Perplexity: 465.6731352013014\n",
            "=== Iteration: 48 ===\n",
            "Alpha: [4.81038166 4.72875891 4.91071368 4.95380207 4.80689839 4.88400193\n",
            " 4.92105957 4.85429517 4.9456987  4.79419493]\n",
            "ELBO: -206211.0105719197\n",
            "Perplexity: 465.48646160917826\n",
            "=== Iteration: 49 ===\n",
            "Alpha: [4.84552951 4.76360565 4.95034792 4.99140554 4.84424136 4.92118697\n",
            " 4.96230901 4.89315259 4.98544508 4.8320154 ]\n",
            "ELBO: -206198.27275254377\n",
            "Perplexity: 465.3098601542192\n",
            "EM Algorithm 끝!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "## ELBO 시각화\n",
        "\n"
      ],
      "metadata": {
        "id": "4MY20Yppt6eN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Inference**"
      ],
      "metadata": {
        "id": "0fdKo5ISwdiC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "## analyze each doc's topic proportion\n",
        "\n",
        "for d, gamma in enumerate(model.gamma):\n",
        "  print(f\"Document {d} topic distribution: {gamma / np.sum(gamma)}\")"
      ],
      "metadata": {
        "id": "QJkH7f5FwhgF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "## analyze topic-word proportion\n",
        "\n",
        "for k, beta in enumerate(model.beta):\n",
        "  top_words = np.argsort(beta)[-10:]\n",
        "  print(f\"Topic {k} top words: {[i_t_v[i] for i in top_words]}\")"
      ],
      "metadata": {
        "id": "xgGQajygwizk"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}

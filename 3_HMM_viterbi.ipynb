{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPd8gKOzLOZR9j9AYodobdv",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/chasubeen/ML_lab/blob/main/3_HMM_viterbi.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import re\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "0c5QVs-_FwjX"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **1. Preprocessing**"
      ],
      "metadata": {
        "id": "90ZRKh3dERdU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1-1. Load data**\n",
        "- CoNLL-2000 file을 읽어와 word(x)와 tag(z) 처리\n",
        "- 특수 품사(`remove_pos`) 제거"
      ],
      "metadata": {
        "id": "_Gx_9utFkNiN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "cUa6BHK3j0_6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "220b56cf-8447-4348-f578-a0857afeb65a"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# data path\n",
        "\n",
        "train_path = \"/content/drive/MyDrive/ML_lab/3_HMM/data/train.txt\"\n",
        "test_path = \"/content/drive/MyDrive/ML_lab/3_HMM/data/test.txt\""
      ],
      "metadata": {
        "id": "TfZ8ZwHjjw6t"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "### Read file\n",
        "\n",
        "def read_file(path):\n",
        "  raw = open(path, 'r').read().strip().split('\\n\\n')  # 빈 줄로 구분된 각 문장 처리\n",
        "  words, tags = [], []\n",
        "\n",
        "  for sentence in raw:\n",
        "    lines = sentence.strip().split('\\n')  # 문장 내의 각 라인 처리\n",
        "    for line in lines:\n",
        "      parts = line.split()  # 열 분할\n",
        "\n",
        "      if len(parts) == 3:\n",
        "        word, pos, chunk = parts\n",
        "        words.append(word.lower())  # 소문자로 변환\n",
        "        tags.append(pos)\n",
        "\n",
        "    # 문장의 끝에 EOS 태그 추가\n",
        "    if words:\n",
        "      words.append('eos')\n",
        "      tags.append('<EOS>')\n",
        "\n",
        "  return words, tags"
      ],
      "metadata": {
        "id": "yLrEXl2J0qSU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_words, train_tags = read_file(train_path)\n",
        "test_words, test_tags = read_file(test_path)"
      ],
      "metadata": {
        "id": "gtY4NX2UJ9wP"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_tags[40:80])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Itp9s2xISnbS",
        "outputId": "20936251-be77-4084-b7ac-c043395dc3b0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['DT', 'NNP', 'NNP', 'NNP', 'POS', 'VBN', 'NN', 'TO', 'DT', 'NN', 'JJ', 'NN', 'VBZ', 'VBN', 'TO', 'VB', 'DT', 'NN', 'IN', 'NN', 'IN', 'DT', 'JJ', 'NN', '.', '<EOS>', 'CC', 'NNS', 'VBP', 'VBG', 'NN', 'IN', 'NN', 'VBZ', 'VBN', 'VBN', 'IN', 'DT', 'NN', 'POS']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_words[40:80])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vn-JwOWzSte9",
        "outputId": "06a2d115-cdcb-4f51-922a-05f93f87c8b2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['the', 'exchequer', 'nigel', 'lawson', \"'s\", 'restated', 'commitment', 'to', 'a', 'firm', 'monetary', 'policy', 'has', 'helped', 'to', 'prevent', 'a', 'freefall', 'in', 'sterling', 'over', 'the', 'past', 'week', '.', 'eos', 'but', 'analysts', 'reckon', 'underlying', 'support', 'for', 'sterling', 'has', 'been', 'eroded', 'by', 'the', 'chancellor', \"'s\"]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1-2. Preprocess Data**"
      ],
      "metadata": {
        "id": "BkJqEkdx3zsO"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **a) 특수 문자 처리**"
      ],
      "metadata": {
        "id": "7PYmlGNBfy6X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def preprocessing(words, tags):\n",
        "  processed_words = []\n",
        "  processed_tags = []\n",
        "\n",
        "  for word, tag in zip(words, tags):\n",
        "\n",
        "    # 모든 숫자의 tag는 'NUM'으로 대체\n",
        "    if re.match(r'^[0-9]*$', word):\n",
        "      tag = 'NUM'\n",
        "\n",
        "    # 빈 문자열이 아닌 경우에만 추가\n",
        "    if word.strip():\n",
        "      processed_words.append(word.lower())  # 소문자 변환\n",
        "      processed_tags.append(tag)\n",
        "\n",
        "  return processed_words, processed_tags"
      ],
      "metadata": {
        "id": "2A5prIu3f6G2"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_words, train_tags = preprocessing(train_words, train_tags)\n",
        "test_words, test_tags = preprocessing(test_words, test_tags)"
      ],
      "metadata": {
        "id": "BQD1CU3HgQaS"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_tags[100:120])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6ed5c7b-cc53-4d53-9a77-31a1380dcc24",
        "id": "CYxwZptdDu2I"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['NN', 'IN', 'DT', 'NN', 'VBG', 'VBN', 'TO', 'VB', 'NN', 'NNS', 'TO', 'NUM', 'NN', 'IN', 'PRP$', 'JJ', 'NUM', 'NN', 'NN', 'TO']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_words[100:120])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f9b7979a-249c-403e-f7f6-53208df309c9",
        "id": "PZLGTSBTDu2J"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['risk', 'of', 'the', 'government', 'being', 'forced', 'to', 'increase', 'base', 'rates', 'to', '16', '%', 'from', 'their', 'current', '15', '%', 'level', 'to']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **b) POS Tag 통합 및 변경**"
      ],
      "metadata": {
        "id": "3RLlPdyogbSA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def modify_tags(tags):\n",
        "  modified_tags = []\n",
        "\n",
        "  for tag in tags:\n",
        "    if tag in ['NN', 'NNS', 'NNP', 'NNPS']:\n",
        "      modified_tags.append('N')\n",
        "\n",
        "    elif tag in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']:\n",
        "      modified_tags.append('V')\n",
        "\n",
        "    elif tag in ['PRP', 'PRP$']:\n",
        "      modified_tags.append('PN')\n",
        "\n",
        "    elif tag in ['IN']:\n",
        "      modified_tags.append('PP')\n",
        "\n",
        "    elif tag in ['RB', 'RBR', 'RBS', 'WRB']:\n",
        "      modified_tags.append('AD')\n",
        "\n",
        "    elif tag in ['CC']:\n",
        "      modified_tags.append('CONJ')\n",
        "\n",
        "    elif tag in ['DT', 'PDT']:\n",
        "      modified_tags.append('ART')\n",
        "\n",
        "    elif tag in ['JJ', 'JJR', 'JJS']:\n",
        "      modified_tags.append('AdJ')\n",
        "\n",
        "    elif tag in ['NUM']:\n",
        "      modified_tags.append('NUM')\n",
        "    elif tag in ['<EOS>']:\n",
        "      modified_tags.append('<EOS>')\n",
        "    else:\n",
        "      modified_tags.append('ETC')\n",
        "\n",
        "  return modified_tags"
      ],
      "metadata": {
        "id": "IKYQMZudgjor"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_tags = modify_tags(train_tags)\n",
        "test_tags = modify_tags(test_tags)"
      ],
      "metadata": {
        "id": "KPe5fAKwg2rM"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(set(train_tags)))\n",
        "print(len(set(test_tags)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeSrgZXlaMgY",
        "outputId": "6014ef83-be19-4dc9-cdd8-7f6fec3606da"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "11\n",
            "11\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "> 11개의 tag로 잘 정리된 것을 확인할 수 있다."
      ],
      "metadata": {
        "id": "JsGSEZaSbfaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_tags[100:120])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a6f86834-1843-43c3-c216-e2897a333b54",
        "id": "jH_W9xRZHmYB"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['N', 'PP', 'ART', 'N', 'V', 'V', 'ETC', 'V', 'N', 'N', 'ETC', 'NUM', 'N', 'PP', 'PN', 'AdJ', 'NUM', 'N', 'N', 'ETC']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_words[100:120])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8d89aa10-2d65-44ed-e142-dc70cf5496b1",
        "id": "9_QzeKlRHmYV"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['risk', 'of', 'the', 'government', 'being', 'forced', 'to', 'increase', 'base', 'rates', 'to', '16', '%', 'from', 'their', 'current', '15', '%', 'level', 'to']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **c) make dictionary**"
      ],
      "metadata": {
        "id": "wXFMcgL1qkhb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def make_dict(tags, words):\n",
        "  tag_to_index = {tag: idx for idx, tag in enumerate(set(tags))}\n",
        "  word_to_index = {word: idx for idx, word in enumerate(set(words))}\n",
        "  return tag_to_index, word_to_index"
      ],
      "metadata": {
        "id": "6S5GSVY8W2Bk"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "combined_words = set(train_words + test_words)\n",
        "combined_tags = set(train_tags + test_tags)"
      ],
      "metadata": {
        "id": "ZrRo1fHaW5yY"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tag_to_index, vocab_to_index = make_dict(combined_tags, combined_words)"
      ],
      "metadata": {
        "id": "RrtSlN6qXChV"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### **e) index 변환**"
      ],
      "metadata": {
        "id": "eDANFZv6-umk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 'UNK' 토큰 추가\n",
        "vocab_to_index['UNK'] = len(vocab_to_index)"
      ],
      "metadata": {
        "id": "w8mlZByQXEwx"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def words_to_indices(words, vocab_to_index):\n",
        "  return [vocab_to_index.get(word, vocab_to_index['UNK']) for word in words]"
      ],
      "metadata": {
        "id": "CG12CcIzt8fJ"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data_idx = words_to_indices(train_words, vocab_to_index)\n",
        "train_tag_idx = [tag_to_index[tag] for tag in train_tags]"
      ],
      "metadata": {
        "id": "Hkc5WtCbuDor"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data_idx = words_to_indices(test_words, vocab_to_index)\n",
        "test_tag_idx = [tag_to_index[tag] for tag in test_tags]"
      ],
      "metadata": {
        "id": "YdgsgdbVuEpN"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## **1-3. 최종 데이터 확인**"
      ],
      "metadata": {
        "id": "QdxBUoO4lUSL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(train_tags[:40])\n",
        "print()\n",
        "print(train_words[:40])"
      ],
      "metadata": {
        "id": "NOnADvaClXam",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c4e184d-d8f7-4205-b5b3-ad9028decfeb"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['N', 'PP', 'ART', 'N', 'V', 'AD', 'V', 'ETC', 'V', 'ART', 'AdJ', 'N', 'PP', 'N', 'N', 'PP', 'N', 'ETC', 'AdJ', 'PP', 'N', 'N', 'ETC', 'V', 'ETC', 'V', 'ART', 'AdJ', 'N', 'PP', 'N', 'CONJ', 'N', 'ETC', 'AdJ', 'N', 'ETC', '<EOS>', 'N', 'PP']\n",
            "\n",
            "['confidence', 'in', 'the', 'pound', 'is', 'widely', 'expected', 'to', 'take', 'another', 'sharp', 'dive', 'if', 'trade', 'figures', 'for', 'september', ',', 'due', 'for', 'release', 'tomorrow', ',', 'fail', 'to', 'show', 'a', 'substantial', 'improvement', 'from', 'july', 'and', 'august', \"'s\", 'near-record', 'deficits', '.', 'eos', 'chancellor', 'of']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **2. Modeling**"
      ],
      "metadata": {
        "id": "FmuTQoGqmta5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class HMM_viterbi:\n",
        "    def __init__(self, num_states, vocab_size, tag_size):\n",
        "        self.num_states = num_states  # Hidden 상태의 개수(POS 태그 개수)\n",
        "        self.vocab_size = vocab_size  # 가능한 단어(x) 목록 크기\n",
        "        self.tag_size = tag_size  # 가능한 POS(z) 목록 크기\n",
        "\n",
        "    def fit(self, X, Z, smoothing=1.0):\n",
        "        # pi 추정\n",
        "        self.pi = np.zeros(self.num_states)  # initial state probabilities\n",
        "        for z in Z:\n",
        "            self.pi[z[0]] += 1\n",
        "        self.pi = (self.pi + smoothing) / (len(Z) + smoothing * self.num_states)\n",
        "\n",
        "        # A 추정(transition probabilities matrix)\n",
        "        self.A = np.zeros((self.num_states, self.num_states))\n",
        "        for z in Z:\n",
        "            for i in range(len(z) - 1):\n",
        "                self.A[z[i], z[i + 1]] += 1\n",
        "        self.A = (self.A + smoothing) / (self.A.sum(axis=1, keepdims=True) + smoothing * self.num_states)\n",
        "\n",
        "        # B 추정(emission probabilities matrix)\n",
        "        self.B = np.zeros((self.num_states, self.vocab_size))\n",
        "        for x, z in zip(X, Z):\n",
        "            for xj, zi in zip(x, z):\n",
        "                self.B[zi, xj] += 1\n",
        "        self.B = (self.B + smoothing) / (self.B.sum(axis=1, keepdims=True) + smoothing * self.vocab_size)\n",
        "\n",
        "    def calculate_likelihood(self, V, t, j, word_idx):\n",
        "        '''\n",
        "        V: log likelihoods until time t\n",
        "        t: current time\n",
        "        j: idx of state at current time\n",
        "        '''\n",
        "        return V[t - 1] + np.log(self.A[:, j]) + np.log(self.B[j, word_idx])\n",
        "\n",
        "    def update_state(self, V, t, j):\n",
        "        '''\n",
        "        V: log likelihoods until time t\n",
        "        t: current time\n",
        "        j: idx of state at current time\n",
        "        '''\n",
        "        return np.argmax(V[t - 1] + np.log(self.A[:, j]))\n",
        "\n",
        "    def get_latent_path(self, X, num_words):\n",
        "        V = np.zeros((num_words, self.num_states))\n",
        "        state_idx = np.zeros((num_words, self.num_states), dtype=int)\n",
        "\n",
        "        # Initialization\n",
        "        V[0] = np.log(self.pi) + np.log(self.B[:, X[0]])\n",
        "\n",
        "        # Recursion\n",
        "        for t in range(1, num_words):\n",
        "            for j in range(self.num_states):\n",
        "                word_idx = X[t]\n",
        "                likelihoods = self.calculate_likelihood(V, t, j, word_idx)\n",
        "                state_idx[t, j] = self.update_state(V, t, j)\n",
        "                V[t, j] = likelihoods[state_idx[t, j]]\n",
        "\n",
        "        # Traceback\n",
        "        z = np.zeros(num_words, dtype=int)\n",
        "        z[-1] = np.argmax(V[-1])\n",
        "        for t in range(num_words - 2, -1, -1):\n",
        "            z[t] = state_idx[t + 1, z[t + 1]]\n",
        "\n",
        "        return z\n",
        "\n",
        "    def predict(self, X):\n",
        "        num_words = len(X)\n",
        "        return self.get_latent_path(X, num_words)\n",
        "\n",
        "    def accuracy(self, z_pred, z_true):\n",
        "        return np.mean(z_pred == z_true)"
      ],
      "metadata": {
        "id": "DNrb5c56nmIf"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **3. Training**"
      ],
      "metadata": {
        "id": "fWvmMRgjnobu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_states = len(tag_to_index)\n",
        "vocab_size = len(vocab_to_index)"
      ],
      "metadata": {
        "id": "fEqaXqPquzpE"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = HMM_viterbi(num_states=num_states, vocab_size=vocab_size, tag_size=num_states)\n",
        "model.fit([train_data_idx], [train_tag_idx], smoothing=1.0)"
      ],
      "metadata": {
        "id": "zA8skjDuXrVr"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_pred_tags = model.predict(train_data_idx)\n",
        "train_accuracy = model.accuracy(train_pred_tags, train_tag_idx)\n",
        "print(f\"Train Accuracy: {train_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3ueMRalvUoy",
        "outputId": "74fe5d99-21c5-44fb-d7e7-f81d6e281901"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Train Accuracy: 0.9435\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **4. Testing**"
      ],
      "metadata": {
        "id": "7Stw8cxCBKAP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test_pred_tags = model.predict(test_data_idx)\n",
        "test_accuracy = model.accuracy(test_pred_tags, test_tag_idx)\n",
        "print(f\"Test Accuracy: {test_accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-07gHlNhvYnf",
        "outputId": "a0dca33d-8567-4de1-ae8a-ad3039945e2c"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test Accuracy: 0.9138\n"
          ]
        }
      ]
    }
  ]
}